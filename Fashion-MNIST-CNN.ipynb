{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CUDA for PyTorch\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "workers = 10\n",
    "\n",
    "traintransform = transforms.Compose([transforms.ToTensor(), \n",
    "                                     transforms.Normalize([0.5,], [0.5,])])\n",
    "\n",
    "testtransform = transforms.Compose([transforms.ToTensor(), transforms.Normalize([0.5,], [0.5,])])\n",
    "\n",
    "trainset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data/', download=True, train=True, transform=traintransform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=workers)\n",
    "\n",
    "testset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data/', download=True, train=False, transform=testtransform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=True, num_workers=workers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image, label = next(iter(trainloader))\n",
    "\n",
    "def showImage(img):\n",
    "    plt.imshow(img.view(28, 28))\n",
    "showImage(image[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool1 = nn.MaxPool2d(3, stride=2, padding=0)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool2 = nn.MaxPool2d(3, stride=2, padding=0)\n",
    "        self.conv4 = nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1)\n",
    "        \n",
    "        self.linear1 = nn.Linear(64*6*6, 512)\n",
    "        self.linear2 = nn.Linear(512, 10)\n",
    "        \n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 1, 28, 28)\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool1(F.relu(self.conv2(x)))\n",
    "        \n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.pool2(F.relu(self.conv4(x)))\n",
    "        \n",
    "        x = x.view(-1, 64*6*6)\n",
    "        x = self.dropout(F.relu(self.linear1(x)))\n",
    "        x = F.log_softmax(self.linear2(x), dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Classifier(\n",
       "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (pool1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (pool2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (linear1): Linear(in_features=2304, out_features=512, bias=True)\n",
       "  (linear2): Linear(in_features=512, out_features=10, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Classifier()\n",
    "model.to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.3042, device='cuda:0', grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.003)\n",
    "\n",
    "image, label = next(iter(trainloader))\n",
    "image = image.to(device)\n",
    "label = label.to(device)\n",
    "image = image.view(image.shape[0], -1)\n",
    "\n",
    "optimizer.zero_grad()\n",
    "\n",
    "out = model.forward(image)\n",
    "criterion(out, label)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\n",
      "test loss: 0.30207884871655966\n",
      "test acc: 0.887937898089172\n",
      "training loss: 0.4342870789407286\n",
      "epoch: 1\n",
      "test loss: 0.2807357281351545\n",
      "test acc: 0.8929140127388535\n",
      "training loss: 0.2747318898119144\n",
      "epoch: 2\n",
      "test loss: 0.2848031620500953\n",
      "test acc: 0.8968949044585988\n",
      "training loss: 0.23958838437951957\n",
      "epoch: 3\n",
      "test loss: 0.2473589887095105\n",
      "test acc: 0.913515127388535\n",
      "training loss: 0.22481625245562367\n",
      "epoch: 4\n",
      "test loss: 0.2562704445545081\n",
      "test acc: 0.90734474522293\n",
      "training loss: 0.20865126355672314\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.003)\n",
    "\n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    test_loss = 0\n",
    "    test_acc = 0\n",
    "    model.train()\n",
    "    for images, labels in trainloader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        images = images.view(images.shape[0], -1)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        out = model.forward(images)\n",
    "        loss = criterion(out, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    else:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for images, labels in testloader:\n",
    "                images = images.to(device)\n",
    "                labels = labels.to(device)\n",
    "                out = model.forward(images)\n",
    "                loss = criterion(out, labels)\n",
    "\n",
    "                modellabel = torch.argmax(out, dim=1)\n",
    "\n",
    "                test_loss += loss.item()\n",
    "                test_acc += float(torch.sum(torch.eq(labels, modellabel))) / float(batch_size)\n",
    "\n",
    "            print(f\"epoch: {e}\")\n",
    "            print(f\"test loss: {test_loss/len(testloader)}\")\n",
    "            print(f\"test acc: {test_acc/len(testloader)}\")\n",
    "            print(f\"training loss: {running_loss/len(trainloader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
