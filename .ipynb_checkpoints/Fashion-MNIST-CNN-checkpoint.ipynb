{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CUDA for PyTorch\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "workers = 10\n",
    "\n",
    "traintransform = transforms.Compose([transforms.RandomHorizontalFlip(p=0.5),\n",
    "                                     transforms.ToTensor(), \n",
    "                                     transforms.Normalize([0.5,], [0.5,])])\n",
    "\n",
    "testtransform = transforms.Compose([transforms.ToTensor(), transforms.Normalize([0.5,], [0.5,])])\n",
    "\n",
    "trainset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data/', download=True, train=True, transform=traintransform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=workers)\n",
    "\n",
    "testset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data/', download=True, train=False, transform=testtransform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=True, num_workers=workers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image, label = next(iter(trainloader))\n",
    "\n",
    "def showImage(img):\n",
    "    plt.imshow(img.view(28, 28))\n",
    "showImage(image[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool1 = nn.MaxPool2d(3, stride=2, padding=0)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.norm1 = nn.BatchNorm2d(64)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool2 = nn.MaxPool2d(3, stride=2, padding=0)\n",
    "        self.conv4 = nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.norm2 = nn.BatchNorm2d(64)\n",
    "        \n",
    "        self.linear1 = nn.Linear(64*6*6, 512)\n",
    "        self.linear2 = nn.Linear(512, 10)\n",
    "        \n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 1, 28, 28)\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool1(self.norm1(F.relu(self.conv2(x))))\n",
    "        \n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.pool2(self.norm1(F.relu(self.conv4(x))))\n",
    "        \n",
    "        x = x.view(-1, 64*6*6)\n",
    "        x = self.dropout(F.relu(self.linear1(x)))\n",
    "        x = F.log_softmax(self.linear2(x), dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Classifier(\n",
       "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (pool1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (pool2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (norm2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (linear1): Linear(in_features=2304, out_features=512, bias=True)\n",
       "  (linear2): Linear(in_features=512, out_features=10, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Classifier()\n",
    "model.to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.3549, device='cuda:0', grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.003)\n",
    "\n",
    "image, label = next(iter(trainloader))\n",
    "image = image.to(device)\n",
    "label = label.to(device)\n",
    "image = image.view(image.shape[0], -1)\n",
    "\n",
    "optimizer.zero_grad()\n",
    "\n",
    "out = model.forward(image)\n",
    "criterion(out, label)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\n",
      "test loss: 0.6312702419651541\n",
      "test acc: 0.776671974522293\n",
      "training loss: 0.4903907878344247\n",
      "epoch: 1\n",
      "test loss: 0.40670109355145956\n",
      "test acc: 0.8491242038216561\n",
      "training loss: 0.3168327934992339\n",
      "epoch: 2\n",
      "test loss: 0.30683496442570046\n",
      "test acc: 0.8878383757961783\n",
      "training loss: 0.2713054388141963\n",
      "epoch: 3\n",
      "test loss: 0.3594529358729435\n",
      "test acc: 0.8641520700636943\n",
      "training loss: 0.24090955661796432\n",
      "epoch: 4\n",
      "test loss: 0.3212543359607648\n",
      "test acc: 0.8821656050955414\n",
      "training loss: 0.22797731029739512\n",
      "epoch: 5\n",
      "test loss: 0.43626623961386407\n",
      "test acc: 0.8572850318471338\n",
      "training loss: 0.20959745077039005\n",
      "epoch: 6\n",
      "test loss: 0.43576934686891594\n",
      "test acc: 0.863156847133758\n",
      "training loss: 0.19791952003119215\n",
      "epoch: 7\n",
      "test loss: 0.4416039245333641\n",
      "test acc: 0.8646496815286624\n",
      "training loss: 0.19003872969733882\n",
      "epoch: 8\n",
      "test loss: 0.5617986644149586\n",
      "test acc: 0.8434514331210191\n",
      "training loss: 0.1782091040926765\n",
      "epoch: 9\n",
      "test loss: 0.6780122225261798\n",
      "test acc: 0.8424562101910829\n",
      "training loss: 0.17520034323130718\n",
      "epoch: 10\n",
      "test loss: 0.49343387578513215\n",
      "test acc: 0.8738057324840764\n",
      "training loss: 0.16404602408949245\n",
      "epoch: 11\n",
      "test loss: 0.5065439640526559\n",
      "test acc: 0.8669386942675159\n",
      "training loss: 0.15961826746778957\n",
      "epoch: 12\n",
      "test loss: 0.492335967007716\n",
      "test acc: 0.8684315286624203\n",
      "training loss: 0.15362215764931778\n",
      "epoch: 13\n",
      "test loss: 0.6282145291756672\n",
      "test acc: 0.8663415605095541\n",
      "training loss: 0.14481190944721958\n",
      "epoch: 14\n",
      "test loss: 0.6370024265377385\n",
      "test acc: 0.8563893312101911\n",
      "training loss: 0.13957962280969377\n",
      "epoch: 15\n",
      "test loss: 0.6357565903739565\n",
      "test acc: 0.8652468152866242\n",
      "training loss: 0.13818355389177672\n",
      "epoch: 16\n",
      "test loss: 1.1141439816754335\n",
      "test acc: 0.8047372611464968\n",
      "training loss: 0.13522322202272125\n",
      "epoch: 17\n",
      "test loss: 0.8637568929772468\n",
      "test acc: 0.8309116242038217\n",
      "training loss: 0.12784750207956794\n",
      "epoch: 18\n",
      "test loss: 1.0592149211342927\n",
      "test acc: 0.8217555732484076\n",
      "training loss: 0.12233562457925284\n",
      "epoch: 19\n",
      "test loss: 1.300179627670604\n",
      "test acc: 0.8058320063694268\n",
      "training loss: 0.12693961389235722\n",
      "epoch: 20\n",
      "test loss: 1.4840074223317918\n",
      "test acc: 0.7972730891719745\n",
      "training loss: 0.11724244658428151\n",
      "epoch: 21\n",
      "test loss: 0.9700464520864426\n",
      "test acc: 0.8317078025477707\n",
      "training loss: 0.11514239885143317\n",
      "epoch: 22\n",
      "test loss: 0.9665356785248799\n",
      "test acc: 0.8366839171974523\n",
      "training loss: 0.11188344513453337\n",
      "epoch: 23\n",
      "test loss: 0.9315992167611031\n",
      "test acc: 0.8209593949044586\n",
      "training loss: 0.10958298566892172\n",
      "epoch: 24\n",
      "test loss: 0.9576958632867807\n",
      "test acc: 0.8326035031847133\n",
      "training loss: 0.10663087288342686\n",
      "epoch: 25\n",
      "test loss: 0.6718827131067872\n",
      "test acc: 0.8649482484076433\n",
      "training loss: 0.10527629538901898\n",
      "epoch: 26\n",
      "test loss: 0.5782468408393632\n",
      "test acc: 0.8681329617834395\n",
      "training loss: 0.1010473427563302\n",
      "epoch: 27\n",
      "test loss: 0.6531423819577618\n",
      "test acc: 0.8629578025477707\n",
      "training loss: 0.09567663827335149\n",
      "epoch: 28\n",
      "test loss: 0.5415503211366902\n",
      "test acc: 0.8886345541401274\n",
      "training loss: 0.0914312891417872\n",
      "epoch: 29\n",
      "test loss: 0.6120190052612192\n",
      "test acc: 0.8756966560509554\n",
      "training loss: 0.09458796486560343\n",
      "epoch: 30\n",
      "test loss: 0.6804565041545471\n",
      "test acc: 0.8687300955414012\n",
      "training loss: 0.09123039624488938\n",
      "epoch: 31\n",
      "test loss: 0.7822291241709594\n",
      "test acc: 0.8512141719745223\n",
      "training loss: 0.09129526806888041\n",
      "epoch: 32\n",
      "test loss: 0.9083652132825487\n",
      "test acc: 0.8477308917197452\n",
      "training loss: 0.08694927319328287\n",
      "epoch: 33\n",
      "test loss: 0.6465460662819018\n",
      "test acc: 0.8727109872611465\n",
      "training loss: 0.08812692077623914\n",
      "epoch: 34\n",
      "test loss: 0.7556476660404995\n",
      "test acc: 0.8602707006369427\n",
      "training loss: 0.08520692172867339\n",
      "epoch: 35\n",
      "test loss: 0.8402211676072923\n",
      "test acc: 0.8675358280254777\n",
      "training loss: 0.07912273748295266\n",
      "epoch: 36\n",
      "test loss: 0.5851653825230659\n",
      "test acc: 0.882265127388535\n",
      "training loss: 0.0840896503892598\n",
      "epoch: 37\n",
      "test loss: 0.7418605457920178\n",
      "test acc: 0.8742038216560509\n",
      "training loss: 0.07774976691477366\n",
      "epoch: 38\n",
      "test loss: 1.0607674703666359\n",
      "test acc: 0.8438495222929936\n",
      "training loss: 0.0794710562845418\n",
      "epoch: 39\n",
      "test loss: 0.6491596518428462\n",
      "test acc: 0.8743033439490446\n",
      "training loss: 0.08247938259308145\n",
      "epoch: 40\n",
      "test loss: 1.1574171644866846\n",
      "test acc: 0.8492237261146497\n",
      "training loss: 0.07030337941455546\n",
      "epoch: 41\n",
      "test loss: 0.8633537071335847\n",
      "test acc: 0.8781847133757962\n",
      "training loss: 0.07836522788667222\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-0bc5177b2725>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mA:\\Programs\\Anaconda\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    116\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m         \"\"\"\n\u001b[1;32m--> 118\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mA:\\Programs\\Anaconda\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m     91\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m     92\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 93\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.003)\n",
    "\n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    test_loss = 0\n",
    "    test_acc = 0\n",
    "    model.train()\n",
    "    for images, labels in trainloader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        images = images.view(images.shape[0], -1)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        out = model.forward(images)\n",
    "        loss = criterion(out, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    else:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for images, labels in testloader:\n",
    "                images = images.to(device)\n",
    "                labels = labels.to(device)\n",
    "                out = model.forward(images)\n",
    "                loss = criterion(out, labels)\n",
    "\n",
    "                modellabel = torch.argmax(out, dim=1)\n",
    "\n",
    "                test_loss += loss.item()\n",
    "                test_acc += float(torch.sum(torch.eq(labels, modellabel))) / float(batch_size)\n",
    "\n",
    "            print(f\"epoch: {e}\")\n",
    "            print(f\"test loss: {test_loss/len(testloader)}\")\n",
    "            print(f\"test acc: {test_acc/len(testloader)}\")\n",
    "            print(f\"training loss: {running_loss/len(trainloader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
