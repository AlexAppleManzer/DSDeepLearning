{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CUDA for PyTorch\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "\n",
    "workers = 10\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize([0.5,], [0.5,])])\n",
    "\n",
    "trainset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data/', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=workers)\n",
    "\n",
    "testset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data/', download=True, train=False, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=True, num_workers=workers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image, label = next(iter(trainloader))\n",
    "\n",
    "def showImage(img):\n",
    "    plt.imshow(img.view(28, 28))\n",
    "\n",
    "showImage(image[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Linear(784, 512)\n",
    "        self.layer2 = nn.Linear(512, 512)\n",
    "        self.layer3 = nn.Linear(512, 512)\n",
    "        self.layer4 = nn.Linear(512, 512)\n",
    "        self.layer5 = nn.Linear(512, 10)\n",
    "        \n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 784)\n",
    "        x = self.dropout(F.relu(self.layer1(x)))\n",
    "        x = self.dropout(F.relu(self.layer2(x)))\n",
    "        x = self.dropout(F.relu(self.layer3(x)))\n",
    "        x = self.dropout(F.relu(self.layer4(x)))\n",
    "        x = F.log_softmax(self.layer5(x), dim=1)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Classifier(\n",
       "  (layer1): Linear(in_features=784, out_features=512, bias=True)\n",
       "  (layer2): Linear(in_features=512, out_features=512, bias=True)\n",
       "  (layer3): Linear(in_features=512, out_features=512, bias=True)\n",
       "  (layer4): Linear(in_features=512, out_features=512, bias=True)\n",
       "  (layer5): Linear(in_features=512, out_features=10, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Classifier()\n",
    "model.to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.3055, device='cuda:0', grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.003)\n",
    "\n",
    "image, label = next(iter(trainloader))\n",
    "image = image.to(device)\n",
    "label = label.to(device)\n",
    "image = image.view(image.shape[0], -1)\n",
    "\n",
    "optimizer.zero_grad()\n",
    "\n",
    "out = model.forward(image)\n",
    "criterion(out, label)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\n",
      "test loss: 1.9576822251081467\n",
      "test acc: 0.19404296875\n",
      "training loss: 2.174175727621038\n",
      "epoch: 1\n",
      "test loss: 1.8309046030044556\n",
      "test acc: 0.194921875\n",
      "training loss: 2.0210503781095466\n",
      "epoch: 2\n",
      "test loss: 1.7911946177482605\n",
      "test acc: 0.19423828125\n",
      "training loss: 2.0067901170000115\n",
      "epoch: 3\n",
      "test loss: 2.3030585169792177\n",
      "test acc: 0.09765625\n",
      "training loss: 2.2487818834629465\n",
      "epoch: 4\n",
      "test loss: 2.302698105573654\n",
      "test acc: 0.09765625\n",
      "training loss: 2.302877858344545\n",
      "epoch: 5\n",
      "test loss: 2.302618157863617\n",
      "test acc: 0.09765625\n",
      "training loss: 2.302834194264513\n",
      "epoch: 6\n",
      "test loss: 2.3026883780956267\n",
      "test acc: 0.09765625\n",
      "training loss: 2.3028435828837943\n",
      "epoch: 7\n",
      "test loss: 2.302778297662735\n",
      "test acc: 0.09765625\n",
      "training loss: 2.3027534789227424\n",
      "epoch: 8\n",
      "test loss: 2.3028162360191344\n",
      "test acc: 0.09765625\n",
      "training loss: 2.3027682740637596\n",
      "epoch: 9\n",
      "test loss: 2.3026765644550324\n",
      "test acc: 0.09765625\n",
      "training loss: 2.302766331205977\n",
      "epoch: 10\n",
      "test loss: 2.302641499042511\n",
      "test acc: 0.09765625\n",
      "training loss: 2.3027998488000097\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-bd0315296809>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtestloader\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m                 \u001b[0mimages\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m                 \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mA:\\Programs\\Anaconda\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    802\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    803\u001b[0m             \u001b[1;32massert\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshutdown\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtasks_outstanding\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 804\u001b[1;33m             \u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    805\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtasks_outstanding\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    806\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mA:\\Programs\\Anaconda\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    769\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    770\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 771\u001b[1;33m                 \u001b[0msuccess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    772\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    773\u001b[0m                     \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mA:\\Programs\\Anaconda\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    722\u001b[0m         \u001b[1;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    723\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 724\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_queue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    725\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mA:\\Programs\\Anaconda\\lib\\multiprocessing\\queues.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m    102\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 104\u001b[1;33m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    105\u001b[0m                         \u001b[1;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m                 \u001b[1;32melif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mA:\\Programs\\Anaconda\\lib\\multiprocessing\\connection.py\u001b[0m in \u001b[0;36mpoll\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 257\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mA:\\Programs\\Anaconda\\lib\\multiprocessing\\connection.py\u001b[0m in \u001b[0;36m_poll\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    328\u001b[0m                         _winapi.PeekNamedPipe(self._handle)[0] != 0):\n\u001b[0;32m    329\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 330\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    331\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    332\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0m_get_more_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mov\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmaxsize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mA:\\Programs\\Anaconda\\lib\\multiprocessing\\connection.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(object_list, timeout)\u001b[0m\n\u001b[0;32m    866\u001b[0m                         \u001b[0mtimeout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    867\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 868\u001b[1;33m             \u001b[0mready_handles\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_exhaustive_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwaithandle_to_obj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    869\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    870\u001b[0m             \u001b[1;31m# request that overlapped reads stop\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mA:\\Programs\\Anaconda\\lib\\multiprocessing\\connection.py\u001b[0m in \u001b[0;36m_exhaustive_wait\u001b[1;34m(handles, timeout)\u001b[0m\n\u001b[0;32m    798\u001b[0m         \u001b[0mready\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    799\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[0mL\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 800\u001b[1;33m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_winapi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mWaitForMultipleObjects\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mL\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    801\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mWAIT_TIMEOUT\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    802\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.003)\n",
    "\n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    test_loss = 0\n",
    "    test_acc = 0\n",
    "    model.train()\n",
    "    for images, labels in trainloader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        images = images.view(images.shape[0], -1)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        out = model.forward(images)\n",
    "        loss = criterion(out, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    else:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for images, labels in testloader:\n",
    "                images = images.to(device)\n",
    "                labels = labels.to(device)\n",
    "                out = model.forward(images)\n",
    "                loss = criterion(out, labels)\n",
    "\n",
    "                modellabel = torch.argmax(out, dim=1)\n",
    "\n",
    "                test_loss += loss.item()\n",
    "                test_acc += float(torch.sum(torch.eq(labels, modellabel))) / float(batch_size)\n",
    "\n",
    "            print(f\"epoch: {e}\")\n",
    "            print(f\"test loss: {test_loss/len(testloader)}\")\n",
    "            print(f\"test acc: {test_acc/len(testloader)}\")\n",
    "            print(f\"training loss: {running_loss/len(trainloader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Sequential(nn.Linear(784, 512),\n",
    "                                    nn.ReLU(),\n",
    "                                    nn.Dropout(0.2),\n",
    "                                    nn.Linear(512, 512),\n",
    "                                    nn.ReLU(),\n",
    "                                    nn.Dropout(0.2),\n",
    "                                    nn.Linear(512, 512),\n",
    "                                    nn.ReLU(),\n",
    "                                    nn.Dropout(0.2),\n",
    "                                    nn.Linear(512, 512),\n",
    "                                    nn.ReLU(),\n",
    "                                    nn.Dropout(0.2),\n",
    "                                    nn.Linear(512, 512),\n",
    "                                    nn.ReLU(),\n",
    "                                    nn.Linear(512,256),\n",
    "                                    nn.LogSoftmax(dim=1))\n",
    "        \n",
    "        self.layer2 = nn.Sequential(nn.Linear(256, 128),\n",
    "                                    nn.ReLU(),\n",
    "                                    nn.Dropout(0.2),\n",
    "                                    nn.Linear(128, 128),\n",
    "                                    nn.ReLU(),\n",
    "                                    nn.Dropout(0.2),\n",
    "                                    nn.Linear(128, 128),\n",
    "                                    nn.ReLU(),\n",
    "                                    nn.Dropout(0.2),\n",
    "                                    nn.Linear(128, 128),\n",
    "                                    nn.ReLU(),\n",
    "                                    nn.Dropout(0.2),\n",
    "                                    nn.Linear(128, 128),\n",
    "                                    nn.ReLU(),\n",
    "                                    nn.Linear(128,128),\n",
    "                                    nn.LogSoftmax(dim=1))\n",
    "        \n",
    "        self.layer3 = nn.Sequential(nn.Linear(128, 64),\n",
    "                                    nn.ReLU(),\n",
    "                                    nn.Dropout(0.2),\n",
    "                                    nn.Linear(64, 64),\n",
    "                                    nn.ReLU(),\n",
    "                                    nn.Dropout(0.2),\n",
    "                                    nn.Linear(64, 64),\n",
    "                                    nn.ReLU(),\n",
    "                                    nn.Dropout(0.2),\n",
    "                                    nn.Linear(64, 64),\n",
    "                                    nn.ReLU(),\n",
    "                                    nn.Dropout(0.2),\n",
    "                                    nn.Linear(64, 64),\n",
    "                                    nn.ReLU(),\n",
    "                                    nn.Linear(64,10),\n",
    "                                    nn.LogSoftmax(dim=1))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 784)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Classifier2(\n",
       "  (layer1): Sequential(\n",
       "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.2, inplace=False)\n",
       "    (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (4): ReLU()\n",
       "    (5): Dropout(p=0.2, inplace=False)\n",
       "    (6): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (7): ReLU()\n",
       "    (8): Dropout(p=0.2, inplace=False)\n",
       "    (9): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (10): ReLU()\n",
       "    (11): Dropout(p=0.2, inplace=False)\n",
       "    (12): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (13): ReLU()\n",
       "    (14): Linear(in_features=512, out_features=256, bias=True)\n",
       "    (15): LogSoftmax()\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.2, inplace=False)\n",
       "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (4): ReLU()\n",
       "    (5): Dropout(p=0.2, inplace=False)\n",
       "    (6): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (7): ReLU()\n",
       "    (8): Dropout(p=0.2, inplace=False)\n",
       "    (9): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (10): ReLU()\n",
       "    (11): Dropout(p=0.2, inplace=False)\n",
       "    (12): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (13): ReLU()\n",
       "    (14): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (15): LogSoftmax()\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.2, inplace=False)\n",
       "    (3): Linear(in_features=64, out_features=64, bias=True)\n",
       "    (4): ReLU()\n",
       "    (5): Dropout(p=0.2, inplace=False)\n",
       "    (6): Linear(in_features=64, out_features=64, bias=True)\n",
       "    (7): ReLU()\n",
       "    (8): Dropout(p=0.2, inplace=False)\n",
       "    (9): Linear(in_features=64, out_features=64, bias=True)\n",
       "    (10): ReLU()\n",
       "    (11): Dropout(p=0.2, inplace=False)\n",
       "    (12): Linear(in_features=64, out_features=64, bias=True)\n",
       "    (13): ReLU()\n",
       "    (14): Linear(in_features=64, out_features=10, bias=True)\n",
       "    (15): LogSoftmax()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Classifier2()\n",
    "model.to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
