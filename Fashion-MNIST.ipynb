{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CUDA for PyTorch\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "\n",
    "workers = 10\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize([0.5,], [0.5,])])\n",
    "\n",
    "trainset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data/', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=workers)\n",
    "\n",
    "testset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data/', download=True, train=False, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=True, num_workers=workers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image, label = next(iter(trainloader))\n",
    "\n",
    "def showImage(img):\n",
    "    plt.imshow(img.view(28, 28))\n",
    "showImage(image[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Linear(784, 512)\n",
    "        self.layer2 = nn.Linear(512, 512)\n",
    "        self.layer5 = nn.Linear(512, 10)\n",
    "        \n",
    "        self.dropout = nn.Dropout(p=0.0)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 784)\n",
    "        x = self.dropout(F.relu(self.layer1(x)))\n",
    "        x = self.dropout(F.relu(self.layer2(x)))\n",
    "        x = F.log_softmax(self.layer5(x), dim=1)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Classifier(\n",
       "  (layer1): Linear(in_features=784, out_features=512, bias=True)\n",
       "  (layer2): Linear(in_features=512, out_features=512, bias=True)\n",
       "  (layer5): Linear(in_features=512, out_features=10, bias=True)\n",
       "  (dropout): Dropout(p=0.0, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Classifier()\n",
    "model.to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.3051, device='cuda:0', grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.003)\n",
    "\n",
    "image, label = next(iter(trainloader))\n",
    "image = image.to(device)\n",
    "label = label.to(device)\n",
    "image = image.view(image.shape[0], -1)\n",
    "\n",
    "optimizer.zero_grad()\n",
    "\n",
    "out = model.forward(image)\n",
    "criterion(out, label)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-e49e051f7f9d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mcriterion\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNLLLoss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.003\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.003)\n",
    "\n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    test_loss = 0\n",
    "    test_acc = 0\n",
    "    model.train()\n",
    "    for images, labels in trainloader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        images = images.view(images.shape[0], -1)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        out = model.forward(images)\n",
    "        loss = criterion(out, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    else:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for images, labels in testloader:\n",
    "                images = images.to(device)\n",
    "                labels = labels.to(device)\n",
    "                out = model.forward(images)\n",
    "                loss = criterion(out, labels)\n",
    "\n",
    "                modellabel = torch.argmax(out, dim=1)\n",
    "\n",
    "                test_loss += loss.item()\n",
    "                test_acc += float(torch.sum(torch.eq(labels, modellabel))) / float(batch_size)\n",
    "\n",
    "            print(f\"epoch: {e}\")\n",
    "            print(f\"test loss: {test_loss/len(testloader)}\")\n",
    "            print(f\"test acc: {test_acc/len(testloader)}\")\n",
    "            print(f\"training loss: {running_loss/len(trainloader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Classifier2()\n",
    "model.to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(testloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
